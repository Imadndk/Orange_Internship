{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecb84b06-7b7f-4545-8e79-e67facf1722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.15.0)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.10/site-packages (2.224.4)\n",
      "Collecting sagemaker\n",
      "  Using cached sagemaker-2.232.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.5)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.24.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (71.0.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.59.3)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Collecting boto3<2.0,>=1.34.142 (from sagemaker)\n",
      "  Using cached boto3-1.35.24-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: docker in /opt/conda/lib/python3.10/site-packages (from sagemaker) (7.1.0)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.10.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.17.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.1.4)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.2.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: pyyaml~=6.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Collecting sagemaker-core<2.0.0,>=1.0.0 (from sagemaker)\n",
      "  Using cached sagemaker_core-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (2.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sagemaker) (4.66.4)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /opt/conda/lib/python3.10/site-packages (from sagemaker) (1.26.19)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting botocore<1.36.0,>=1.35.24 (from boto3<2.0,>=1.34.142->sagemaker)\n",
      "  Using cached botocore-1.35.24-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0,>=1.34.142->sagemaker) (0.10.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.19.2)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow)\n",
      "  Using cached optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker-core<2.0.0,>=1.0.0->sagemaker) (1.10.16)\n",
      "Collecting mock<5.0,>4.0 (from sagemaker-core<2.0.0,>=1.0.0->sagemaker)\n",
      "  Using cached mock-4.0.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.20.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Using cached tensorflow-2.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
      "Using cached sagemaker-2.232.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached boto3-1.35.24-py3-none-any.whl (139 kB)\n",
      "Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "Using cached ml_dtypes-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached sagemaker_core-1.0.7-py3-none-any.whl (384 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Using cached botocore-1.35.24-py3-none-any.whl (12.6 MB)\n",
      "Using cached mock-4.0.3-py3-none-any.whl (28 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (347 kB)\n",
      "Installing collected packages: namex, libclang, tensorflow-io-gcs-filesystem, optree, mock, ml-dtypes, tensorboard, botocore, keras, tensorflow, boto3, sagemaker-core, sagemaker\n",
      "  Attempting uninstall: mock\n",
      "    Found existing installation: mock 5.1.0\n",
      "    Uninstalling mock-5.1.0:\n",
      "      Successfully uninstalled mock-5.1.0\n",
      "  Attempting uninstall: ml-dtypes\n",
      "    Found existing installation: ml-dtypes 0.2.0\n",
      "    Uninstalling ml-dtypes-0.2.0:\n",
      "      Successfully uninstalled ml-dtypes-0.2.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.2\n",
      "    Uninstalling tensorboard-2.15.2:\n",
      "      Successfully uninstalled tensorboard-2.15.2\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.131\n",
      "    Uninstalling botocore-1.34.131:\n",
      "      Successfully uninstalled botocore-1.34.131\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.15.0\n",
      "    Uninstalling keras-2.15.0:\n",
      "      Successfully uninstalled keras-2.15.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.15.0\n",
      "    Uninstalling tensorflow-2.15.0:\n",
      "      Successfully uninstalled tensorflow-2.15.0\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.131\n",
      "    Uninstalling boto3-1.34.131:\n",
      "      Successfully uninstalled boto3-1.34.131\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.224.4\n",
      "    Uninstalling sagemaker-2.224.4:\n",
      "      Successfully uninstalled sagemaker-2.224.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.13.1 requires botocore<1.34.132,>=1.34.70, but you have botocore 1.35.24 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.1 which is incompatible.\n",
      "autogluon-common 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-core 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-features 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-features 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires pytorch-lightning<1.10.0,>=1.9.0, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchmetrics<0.12.0,>=0.11.0, but you have torchmetrics 1.0.3 which is incompatible.\n",
      "autogluon-multimodal 0.8.3 requires torchvision<0.15.0, but you have torchvision 0.15.2a0+ab7b3e6 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-tabular 0.8.3 requires scikit-learn<1.4.1,>=1.1, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pandas<1.6,>=1.4.1, but you have pandas 2.1.4 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires pytorch-lightning<1.10.0,>=1.7.4, but you have pytorch-lightning 2.0.9 which is incompatible.\n",
      "autogluon-timeseries 0.8.3 requires torch<1.14,>=1.9, but you have torch 2.0.0.post104 which is incompatible.\n",
      "langchain-aws 0.1.6 requires boto3<1.35.0,>=1.34.51, but you have boto3 1.35.24 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.35.24 botocore-1.35.24 keras-3.5.0 libclang-18.1.1 ml-dtypes-0.4.1 mock-4.0.3 namex-0.0.8 optree-0.12.1 sagemaker-2.232.1 sagemaker-core-1.0.7 tensorboard-2.17.1 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ec91c6-4e3a-44b6-9cfd-56f82da2206b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 20:08:40.912599: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-23 20:08:40.915786: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-23 20:08:40.925802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-23 20:08:40.943483: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-23 20:08:40.948684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-23 20:08:40.961191: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-23 20:08:41.916122: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-eu-west-3-024848443248\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "from sagemaker.utils import S3DataConfig\n",
    "\n",
    "import shutil\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_session = sagemaker.Session()\n",
    "bucket_name = sm_session.default_bucket()\n",
    "prefix = \"sagemaker/modelLSTM\"\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f0f504c-720a-47b0-bd43-422cb84b956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 20:08:46.981707: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 133434000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13238/13238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 7ms/step - accuracy: 0.8017 - loss: 0.6814 - val_accuracy: 0.8220 - val_loss: 0.6272\n",
      "Epoch 2/50\n",
      "\u001b[1m13238/13238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 7ms/step - accuracy: 0.8148 - loss: 0.6474 - val_accuracy: 0.8233 - val_loss: 0.6251\n",
      "Epoch 3/50\n",
      "\u001b[1m13238/13238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 7ms/step - accuracy: 0.8145 - loss: 0.6482 - val_accuracy: 0.8234 - val_loss: 0.6239\n",
      "Epoch 4/50\n",
      "\u001b[1m13238/13238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 7ms/step - accuracy: 0.8147 - loss: 0.6474 - val_accuracy: 0.8235 - val_loss: 0.6245\n",
      "Epoch 5/50\n",
      "\u001b[1m13238/13238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 7ms/step - accuracy: 0.8149 - loss: 0.6469 - val_accuracy: 0.8232 - val_loss: 0.6258\n",
      "Epoch 6/50\n",
      "\u001b[1m13238/13238\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 7ms/step - accuracy: 0.8156 - loss: 0.6439 - val_accuracy: 0.8232 - val_loss: 0.6257\n",
      "\u001b[1m5430/5430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8134 - loss: 0.6489\n",
      "Test Loss: 0.65, Test Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "df = pd.read_csv('urgency_cases_data_large_multiclass (2).csv')\n",
    "data = df.drop(columns=['patient_id'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data[['heart_rate', 'respiratory_rate', 'blood_pressure_diastolic','blood_pressure_systolic', 'oxygen_saturation', 'body_temperature']])\n",
    "def create_sequences(dataa, target, time_steps=10, lead_time=10): \n",
    "    X, y = [], []\n",
    "    for i in range(len(dataa) - time_steps - lead_time):\n",
    "        X.append(dataa[i:(i + time_steps)])\n",
    "        y.append(target[i + time_steps + lead_time])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_steps = 10\n",
    "X, y = create_sequences(scaled_data, data['urgency'].values, time_steps)\n",
    "y = to_categorical(y, num_classes=4)\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(time_steps, X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=42, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.2f}, Test Accuracy: {accuracy:.2f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f78e914b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Optimize.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Optimize.py\n",
    "def create_model(units=50, dropout_rate=0.2, batch_size=32, epochs=50, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(time_steps, X.shape[2]), return_sequences=True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=50, batch_size=32, verbose=0, dropout_rate=0.2, units=50, optimizer='adam')\n",
    "\n",
    "param_grid = {\n",
    "    'units': [50, 100],\n",
    "    'dropout_rate': [0.2, 0.3],\n",
    "    'optimizer': ['adam', 'rmsprop'],\n",
    "    'batch_size': [32, 40],\n",
    "    'epochs': [30, 50]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "best_model = grid_result.best_estimator_.model\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.2f}, Test Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4478adc8-040e-4ccf-b1d7-a0a2ff8d47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_real_time(model, new_data, lead_time=10):\n",
    "    scaled_new_data = scaler.transform(new_data)\n",
    "    sequences = []\n",
    "    for i in range(len(scaled_new_data) - time_steps - lead_time + 1):\n",
    "        sequences.append(scaled_new_data[i:(i + time_steps)])\n",
    "    sequences = np.array(sequences)\n",
    "    predictions = model.predict(sequences)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "114e8b7b-1b89-4fcb-a05c-9c394fc75d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n",
    "save_model(model, 'lstm_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd32fcad-ced3-419f-b042-8c9169d9953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/Servo/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: export/Servo/1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'export/Servo/1'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 6), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 4), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140371869999600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371869997488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371870001712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371869766000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371869767408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371869769168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371869776560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140371869777264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export(\"export/Servo/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fc97e7-659c-4db0-bab4-2d575b9eb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as tar:\n",
    "    tar.add(\"export\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c4b2a2-add2-417a-8bda-2fe39de19b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_response = sm_session.upload_data(\"model.tar.gz\", bucket=bucket_name, key_prefix=\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c7a58e-d8d2-48a0-8783-5b8952223fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model_path = os.path.join(model_dir, 'export', 'Servo', '1', 'lstm_model.keras')\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, content_type, time_steps=10):\n",
    "    if content_type == 'application/json':\n",
    "        request = json.loads(request_body)\n",
    "        data = pd.DataFrame(request)\n",
    "    elif content_type == 'text/csv':\n",
    "        data = pd.read_csv(io.StringIO(request_body), header=None)\n",
    "    elif content_type == 'application/x-npy':\n",
    "        stream = BytesIO(request_body)\n",
    "        data = np.load(stream)\n",
    "        data = pd.DataFrame(data)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported content type: {content_type}')\n",
    "    X = []\n",
    "    for i in range(len(data) - time_steps):\n",
    "        X.append(data.iloc[i:(i + time_steps)].values) \n",
    "    return np.array(X)\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    predictions = model.predict(input_data) \n",
    "    return predictions\n",
    "\n",
    "def output_fn(prediction, content_type):\n",
    "    response = prediction.tolist()\n",
    "    return json.dumps(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cad9b9e-bdda-4370-a969-cbd39196fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_model = TensorFlowModel(\n",
    "    model_data=f\"s3://{bucket_name}/model/model.tar.gz\",\n",
    "    role=role,\n",
    "    framework_version=\"2.16\",\n",
    "    entry_point= 'train.py'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573b8eba-b5eb-4795-9878-2baaa6159ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!CPU times: user 297 ms, sys: 47.7 ms, total: 345 ms\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = sagemaker_model.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a941f9e-50f0-474b-8516-8bd6614c556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint='tensorflow-inference-2024-09-23-20-20-30-511'\n",
    "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(endpoint, sm_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d9156b-87be-4a3e-a5c0-f5f568103b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [[0.11210607, 0.0232726652, 0.037591733, 0.827029586]]}\n"
     ]
    }
   ],
   "source": [
    "result=predictor.predict(np.array([[\n",
    "    [85, 18, 140, 90, 37.0, 98],\n",
    "    [88, 18, 142, 92, 37.1, 97],\n",
    "    [90, 19, 145, 94, 37.2, 96],\n",
    "    [92, 19, 147, 95, 37.3, 95],\n",
    "    [94, 20, 150, 97, 37.4, 94],\n",
    "    [96, 20, 152, 98, 37.5, 93],\n",
    "    [98, 21, 155, 100, 37.6, 92],\n",
    "    [100, 21, 157, 102, 37.7, 91],\n",
    "    [102, 22, 160, 103, 37.8, 90],\n",
    "    [104, 22, 162, 105, 37.9, 89]\n",
    "]]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bfabbd3-7efc-4882-a9c7-5fddcf14c937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.11210604, 0.0232726596, 0.0375917293, 0.827029526],\n",
       "  [0.108835287, 0.0232997891, 0.0373404324, 0.830524504],\n",
       "  [0.104884014, 0.0234275758, 0.037259344, 0.834429085],\n",
       "  [0.104352511, 0.0220787786, 0.0340504237, 0.839518368],\n",
       "  [0.102130376, 0.0215444732, 0.035568729, 0.840756416],\n",
       "  [0.102318302, 0.0216496885, 0.0358752161, 0.840156794],\n",
       "  [0.10213802, 0.0218241308, 0.0362785, 0.83975935],\n",
       "  [0.102666594, 0.0219462961, 0.0363970064, 0.838990211],\n",
       "  [0.103227541, 0.0220625456, 0.0365837589, 0.838126063],\n",
       "  [0.105437182, 0.0223772824, 0.0367264301, 0.835459173],\n",
       "  [0.132447973, 0.0302486159, 0.0376081578, 0.799695253],\n",
       "  [0.171072423, 0.0406888835, 0.0381986164, 0.750040054],\n",
       "  [0.191057146, 0.040819522, 0.0384506918, 0.729672551],\n",
       "  [0.205713317, 0.0398204289, 0.0387327261, 0.715733588],\n",
       "  [0.214534834, 0.0397323556, 0.0389994, 0.706733346],\n",
       "  [0.222597122, 0.0397190973, 0.0390701629, 0.698613644],\n",
       "  [0.227318063, 0.0396663137, 0.0392571799, 0.693758309],\n",
       "  [0.231205329, 0.039691817, 0.039275296, 0.689827561],\n",
       "  [0.232797936, 0.0397109091, 0.0395279564, 0.687963188],\n",
       "  [0.235741019, 0.039639838, 0.0394095592, 0.685209513],\n",
       "  [0.233945757, 0.0392938741, 0.0398690291, 0.686891258],\n",
       "  [0.234877273, 0.0388976336, 0.0397386141, 0.686486483],\n",
       "  [0.232552871, 0.0389364026, 0.0400309, 0.688479841],\n",
       "  [0.232152909, 0.0389793292, 0.0398456305, 0.689022183],\n",
       "  [0.23049745, 0.0391576625, 0.0400211699, 0.69032371],\n",
       "  [0.229793757, 0.0397726595, 0.0399662852, 0.690467298],\n",
       "  [0.228581369, 0.0400605127, 0.0399500951, 0.691408098],\n",
       "  [0.227783248, 0.0402013324, 0.0398533195, 0.692162097],\n",
       "  [0.226725578, 0.0404583588, 0.040125791, 0.692690253],\n",
       "  [0.226301938, 0.0404185951, 0.0399508849, 0.693328559]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_real_time(model, new_data, lead_time=10):\n",
    "    sequences = []\n",
    "    for i in range(len(new_data) - time_steps - lead_time + 1):\n",
    "        sequences.append(new_data[i:(i + time_steps)])\n",
    "    sequences = np.array(sequences)\n",
    "    predictions = model.predict(sequences)\n",
    "    return predictions\n",
    "predict_real_time(predictor,new_patient_data, lead_time=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9a4fc6e-1e9d-4412-8322-a4f86fb4e2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': [[0.0296158772, 0.148461133, 0.0191821288, 0.802740812],\n",
       "  [0.0313914865, 0.169540748, 0.0207802542, 0.77828759],\n",
       "  [0.0337662, 0.192175627, 0.0219418947, 0.752116323],\n",
       "  [0.0375614613, 0.221397132, 0.0230047032, 0.718036771],\n",
       "  [0.0433702022, 0.260551214, 0.0236050449, 0.672473669],\n",
       "  [0.0499644503, 0.305658132, 0.0240579862, 0.620319426],\n",
       "  [0.0569920316, 0.35484919, 0.0242628232, 0.563896],\n",
       "  [0.0651943609, 0.414125085, 0.0241511874, 0.496529311],\n",
       "  [0.0762244165, 0.483157188, 0.0231686514, 0.417449743],\n",
       "  [0.0886544511, 0.552740693, 0.0216104165, 0.33699438],\n",
       "  [0.100148931, 0.60572958, 0.0202674102, 0.273854047],\n",
       "  [0.105498917, 0.634870648, 0.0199435558, 0.239686772],\n",
       "  [0.109200336, 0.656055748, 0.0198906455, 0.214853302],\n",
       "  [0.118686, 0.672493279, 0.019504264, 0.189316452],\n",
       "  [0.137719646, 0.680163622, 0.01821783, 0.163898796],\n",
       "  [0.181736767, 0.665857911, 0.016491618, 0.135913655],\n",
       "  [0.281589359, 0.595623493, 0.0152968476, 0.107490189],\n",
       "  [0.417899609, 0.477925, 0.0157875065, 0.0883877799],\n",
       "  [0.504813313, 0.396457881, 0.016094882, 0.0826339796],\n",
       "  [0.564592302, 0.340604454, 0.0160510466, 0.0787522122],\n",
       "  [0.612034619, 0.295436114, 0.0160239749, 0.0765053332],\n",
       "  [0.652883172, 0.257222742, 0.0160845984, 0.0738093629],\n",
       "  [0.68152523, 0.230250716, 0.0165632982, 0.0716607],\n",
       "  [0.697991192, 0.214665771, 0.0168619175, 0.070481129],\n",
       "  [0.707928419, 0.205155194, 0.0168182775, 0.0700980499],\n",
       "  [0.717878699, 0.196279496, 0.0162783284, 0.0695634931],\n",
       "  [0.720076859, 0.194828257, 0.0159310699, 0.0691637397],\n",
       "  [0.718497694, 0.195142925, 0.0157909635, 0.070568338],\n",
       "  [0.71879673, 0.190709293, 0.0152837289, 0.0752102286],\n",
       "  [0.720644593, 0.184032828, 0.0145506188, 0.080772005]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_real_time(model, new_data, lead_time=10):\n",
    "    scaled_new_data = scaler.transform(new_data)\n",
    "    sequences = []\n",
    "    for i in range(len(scaled_new_data) - time_steps - lead_time + 1):\n",
    "        sequences.append(scaled_new_data[i:(i + time_steps)])\n",
    "    sequences = np.array(sequences)\n",
    "    predictions = model.predict(sequences)\n",
    "    return predictions\n",
    "predict_real_time(predictor,new_patient_data, lead_time=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93fe64ef-d488-44b1-afc7-705ba74ab7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_patient_data = np.array([\n",
    "    [85, 18, 140, 90, 37.0, 98],\n",
    "    [88, 18, 142, 92, 37.1, 97],\n",
    "    [90, 19, 145, 94, 37.2, 96],\n",
    "    [92, 19, 147, 95, 37.3, 95],\n",
    "    [94, 20, 150, 97, 37.4, 94],\n",
    "    [96, 20, 152, 98, 37.5, 93],\n",
    "    [98, 21, 155, 100, 37.6, 92],\n",
    "    [100, 21, 157, 102, 37.7, 91],\n",
    "    [102, 22, 160, 103, 37.8, 90],\n",
    "    [104, 22, 162, 105, 37.9, 89],\n",
    "    [106, 23, 165, 107, 38.0, 88],\n",
    "    [108, 23, 167, 108, 38.1, 87],\n",
    "    [110, 24, 170, 110, 38.2, 86],\n",
    "    [112, 24, 172, 112, 38.3, 85],\n",
    "    [114, 25, 175, 113, 38.4, 84],\n",
    "    [116, 25, 177, 115, 38.5, 83],\n",
    "    [118, 26, 180, 117, 38.6, 82],\n",
    "    [120, 26, 182, 118, 38.7, 81],\n",
    "    [122, 27, 185, 120, 38.8, 80],\n",
    "    [124, 27, 187, 122, 38.9, 79],\n",
    "    [126, 28, 190, 123, 39.0, 78],\n",
    "    [128, 28, 192, 125, 39.1, 77],\n",
    "    [130, 29, 195, 127, 39.2, 76],\n",
    "    [132, 29, 197, 128, 39.3, 75],\n",
    "    [134, 30, 200, 130, 39.4, 74],\n",
    "    [136, 30, 202, 132, 39.5, 73],\n",
    "    [138, 31, 205, 133, 39.6, 72],\n",
    "    [140, 31, 207, 135, 39.7, 71],\n",
    "    [142, 32, 210, 137, 39.8, 70],\n",
    "    [144, 32, 212, 138, 39.9, 69],\n",
    "    [146, 33, 215, 140, 40.0, 68],\n",
    "    [148, 33, 217, 142, 40.1, 67],\n",
    "    [150, 34, 220, 143, 40.2, 66],\n",
    "    [152, 34, 222, 145, 40.3, 65],\n",
    "    [154, 35, 225, 147, 40.4, 64],\n",
    "    [156, 35, 227, 148, 40.5, 63],\n",
    "    [158, 36, 230, 150, 40.6, 62],\n",
    "    [160, 36, 232, 152, 40.7, 61],\n",
    "    [162, 37, 235, 153, 40.8, 60],\n",
    "    [164, 37, 237, 155, 40.9, 59],\n",
    "    [166, 38, 240, 157, 41.0, 58],\n",
    "    [168, 38, 242, 158, 41.1, 57],\n",
    "    [170, 39, 245, 160, 41.2, 56],\n",
    "    [172, 39, 247, 162, 41.3, 55],\n",
    "    [174, 40, 250, 163, 41.4, 54],\n",
    "    [176, 40, 252, 165, 41.5, 53],\n",
    "    [178, 41, 255, 167, 41.6, 52],\n",
    "    [180, 41, 257, 168, 41.7, 51],\n",
    "    [182, 42, 260, 170, 41.8, 50]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada29f65-cedd-43da-a974-2b642a0485b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  20/5430 [..............................] - ETA: 28s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 11:34:24.026988: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 41698320 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5430/5430 [==============================] - 29s 5ms/step\n",
      "Confusion Matrix:\n",
      " [[78664  4198  4516  4548]\n",
      " [ 4328 19416  1003   841]\n",
      " [ 4550   974 21340  1023]\n",
      " [ 4596   926   981 21839]]\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     No Event       0.85      0.86      0.85     91926\n",
      " Heart Attack       0.76      0.76      0.76     25588\n",
      "Hyperglycemia       0.77      0.77      0.77     27887\n",
      " Hypoglycemia       0.77      0.77      0.77     28342\n",
      "\n",
      "     accuracy                           0.81    173743\n",
      "    macro avg       0.79      0.79      0.79    173743\n",
      " weighted avg       0.81      0.81      0.81    173743\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "report = classification_report(y_test_classes, y_pred_classes, target_names=['No Event', 'Heart Attack', 'Hyperglycemia', 'Hypoglycemia'])\n",
    "print('Classification Report:\\n', report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8bddde-ef41-49dd-a15c-529a7f444423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf605486-5e61-4919-89b3-d2edea53e9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
